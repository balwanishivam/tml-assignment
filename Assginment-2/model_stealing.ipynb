{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_0 = torch.load('./dataset_cluster_0.pt')\n",
    "dataset_1 = torch.load('./dataset_cluster_1.pt')\n",
    "images_0 = dataset_0.images\n",
    "images_1 = dataset_1.images\n",
    "batch_0 = len(images_0)//1000\n",
    "batch_1 = len(images_1)//1000\n",
    "print(batch_0, batch_1)\n",
    "images_0 = images_0[:batch_0*1000]\n",
    "images_1 = images_1[:batch_1*1000]\n",
    "print(len(images_0), len(images_1))\n",
    "images = images_0 + images_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepresentationDataset(Dataset):\n",
    "    def __init__(self, images, rep):\n",
    "        self.images = images\n",
    "        self.representation = rep\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.representation[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivambalwani/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shivambalwani/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(self, encoder, projector_dim=1024, dropout_prob=0.5):\n",
    "        super(SimSiam, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(encoder.fc.in_features, projector_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(projector_dim, projector_dim),\n",
    "            nn.Dropout(dropout_prob)\n",
    "        )\n",
    "        self.encoder.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        projections = self.projector(features)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_loss(output, target):\n",
    "    output = F.normalize(output, dim=-1)\n",
    "    target = F.normalize(target, dim=-1)\n",
    "    return -torch.mean(torch.sum(output * target, dim=-1))\n",
    "\n",
    "criterion = cosine_similarity_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivambalwani/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shivambalwani/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "encoder = resnet18(pretrained=False)\n",
    "denoise_model = SimSiam(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./encoder.pt\")\n",
    "denoise_model.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_representations = torch.load('./denoised_feature_vectors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_representations = denoised_representations.reshape(-1, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12000, 1024])\n",
      "tensor([-0.0349, -0.0349, -0.0349,  ..., -0.0349, -0.0349, -0.0349])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(denoised_representations.shape)\n",
    "print(denoised_representations[0])\n",
    "print(type(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_dataset = RepresentationDataset(images, denoised_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_dataloader = DataLoader(denoised_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: -0.0008\n",
      "Epoch [2/20], Loss: -0.0012\n",
      "Epoch [3/20], Loss: -0.0007\n",
      "Epoch [4/20], Loss: -0.0002\n",
      "Epoch [5/20], Loss: -0.0004\n",
      "Epoch [6/20], Loss: -0.0023\n",
      "Epoch [7/20], Loss: -0.0006\n",
      "Epoch [8/20], Loss: -0.0011\n",
      "Epoch [9/20], Loss: -0.0001\n",
      "Epoch [10/20], Loss: -0.0015\n",
      "Epoch [11/20], Loss: -0.0008\n",
      "Epoch [12/20], Loss: -0.0007\n",
      "Epoch [13/20], Loss: -0.0015\n",
      "Epoch [14/20], Loss: -0.0017\n",
      "Epoch [15/20], Loss: -0.0002\n",
      "Epoch [16/20], Loss: -0.0010\n",
      "Epoch [17/20], Loss: -0.0005\n",
      "Epoch [18/20], Loss: -0.0020\n",
      "Epoch [19/20], Loss: 0.0001\n",
      "Epoch [20/20], Loss: -0.0017\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for images, representations in denoised_dataloader:\n",
    "        outputs = denoise_model(images)\n",
    "        loss = criterion(outputs[0].unsqueeze(0), representations[0].unsqueeze(0))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(images)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(denoise_model, \"denoised_encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    denoise_model,\n",
    "    torch.randn(1, 3, 32, 32),\n",
    "    './stolen_model.onnx',\n",
    "    export_params=True,\n",
    "    input_names=[\"x\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stolen_model.onnx', \"rb\") as f:\n",
    "    model = f.read()\n",
    "    try:\n",
    "        stolen_model = ort.InferenceSession(model)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid model, {e=}\")\n",
    "    try:\n",
    "        out = stolen_model.run(\n",
    "            None, {\"x\": np.random.randn(1, 3, 32, 32).astype(np.float32)}\n",
    "        )[0][0]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Some issue with the input, {e=}\")\n",
    "    assert out.shape == (1024,), \"Invalid output shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detail': 'Exceeded submissions. Only 1/h allowed.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "SEED = '20499754'\n",
    "PORT = '9052'\n",
    "response = requests.post(\"http://34.71.138.79:9090/stealing\", files={\"file\": open('./stolen_model.onnx', \"rb\")}, headers={\"token\": \"40034445\", \"seed\": SEED})\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
