{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset \n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n",
    "class MembershipDataset(TaskDataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super().__init__(transform)\n",
    "        self.membership = []\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int, int]:\n",
    "        id_, img, label = super().__getitem__(index)\n",
    "        return id_, img, label, self.membership[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "public_dataset: MembershipDataset(transform=transform) = torch.load(\"./pub.pt\")\n",
    "public_dataset = DataLoader(public_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_res18 = models.resnet18(pretrained=False)\n",
    "shadow_model_res18.fc = nn.Linear(512, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_res18.pt\")\n",
    "shadow_model_res18.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_vgg = models.vgg16(pretrained=False)\n",
    "shadow_model_vgg.classifier[6] = nn.Linear(4096, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_vgg.pt\")\n",
    "shadow_model_vgg.load_state_dict(checkpoint.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_dense = models.densenet121(pretrained=False)\n",
    "shadow_model_dense.classifier = nn.Linear(1024, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_dense.pt\")\n",
    "shadow_model_dense.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_resnext = models.resnext50_32x4d(pretrained=False)\n",
    "shadow_model_resnext.fc = nn.Linear(2048, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_resnext.pt\")\n",
    "shadow_model_resnext.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_effnet = models.efficientnet_b0(pretrained=False)\n",
    "shadow_model_effnet.classifier[1] = nn.Linear(1280, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_effnet.pt\")\n",
    "shadow_model_effnet.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_mobilenet = models.mobilenet_v2(pretrained=False)\n",
    "shadow_model_mobilenet.classifier[1] = nn.Linear(1280, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_mobilenet.pt\")\n",
    "shadow_model_mobilenet.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_squeezenet = models.squeezenet1_0(pretrained=False)\n",
    "shadow_model_squeezenet.classifier[1] = nn.Conv2d(512, 44, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_squeezenet.pt\")\n",
    "shadow_model_squeezenet.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_res34 = models.resnet34(pretrained=False)\n",
    "shadow_model_res34.fc = nn.Linear(512, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_res34.pt\")\n",
    "shadow_model_res34.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_dense_adamw = models.densenet121(pretrained=False)\n",
    "shadow_model_dense_adamw.classifier = nn.Linear(1024, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_dense_adamw.pt\")\n",
    "shadow_model_dense_adamw.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_res18_sgd = models.resnet18(pretrained=False)\n",
    "shadow_model_res18_sgd.fc = nn.Linear(512, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_res18_sgd.pt\")\n",
    "shadow_model_res18_sgd.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_model_shufflenet = models.shufflenet_v2_x1_0(pretrained=False)\n",
    "shadow_model_shufflenet.fc = nn.Linear(1024, 44)\n",
    "\n",
    "checkpoint = torch.load(\"./shadow_model_shufflenet.pt\")\n",
    "shadow_model_shufflenet.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, data_loader):\n",
    "    model.eval() \n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    member_list = []\n",
    "    with torch.no_grad():\n",
    "        for ids, inputs, labels, membership in data_loader:\n",
    "            features = model(inputs).cpu().numpy()\n",
    "            features_list.append(features)\n",
    "            labels_list.append(labels.numpy())\n",
    "            member_list.append(membership.numpy())\n",
    "    features = np.concatenate(features_list)\n",
    "    labels = np.concatenate(labels_list)\n",
    "    membership = np.concatenate(member_list)\n",
    "    return features, labels, membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_models = [\n",
    "    shadow_model_res18, \n",
    "    shadow_model_vgg, \n",
    "    shadow_model_dense, \n",
    "    shadow_model_effnet, \n",
    "    shadow_model_resnext, \n",
    "    shadow_model_mobilenet,\n",
    "    shadow_model_squeezenet,\n",
    "    shadow_model_shufflenet,\n",
    "    shadow_model_res18_sgd,\n",
    "    shadow_model_dense_adamw,\n",
    "    shadow_model_res34\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_3549069/795879585.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  X_train_tensor = torch.tensor(X_train_list, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for shadow_model in shadow_models:\n",
    "    features, _, membership = extract_features(shadow_model, public_dataset)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, membership, test_size=0.15, random_state=42)\n",
    "    X_train_list.extend(X_train) \n",
    "    y_train_list.extend(y_train)  \n",
    "    X_test_list.extend(X_test)    \n",
    "    y_test_list.extend(y_test)    \n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_list, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_list, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_list, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_list, dtype=torch.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_tensor)\n",
    "X_test_scaled = scaler.transform(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187000, 44)\n",
      "(33000, 44)\n",
      "torch.Size([187000])\n",
      "torch.Size([33000])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)\n",
    "print(y_train_tensor.shape)\n",
    "print(y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "\n",
    "# # Suppress all warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import numpy as np\n",
    "\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200, 300],\n",
    "#     'max_depth': [None, 10, 20, 30, 40],\n",
    "#     'min_samples_split': [2, 5, 10, 15],\n",
    "#     'min_samples_leaf': [1, 2, 4, 6],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2']\n",
    "# }\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "# best_rf = grid_search.best_estimator_\n",
    "# y_pred_proba = best_rf.predict_proba(X_test_scaled)\n",
    "# logits = np.log(y_pred_proba[:, 1] / (1 - y_pred_proba[:, 1]))\n",
    "# threshold = 0\n",
    "# y_pred = (logits > threshold).astype(int)\n",
    "# print(y_pred)\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "# print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "# print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "# print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', log_reg),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('svc', SVC(probability=True))\n",
    "], voting='soft')\n",
    "\n",
    "print(\"Starting Training\")\n",
    "voting_clf.fit(X_train_scaled, y_train_tensor)\n",
    "print(\"Finished Training\")\n",
    "print(\"Starting Evaluation\")\n",
    "y_pred_voting = voting_clf.predict_proba(X_test_scaled)\n",
    "logits_voting = np.log(y_pred_voting[:, 1] / (1 - y_pred_voting[:, 1]))\n",
    "threshold = 0\n",
    "y_pred_voting = (logits_voting > threshold).astype(int)\n",
    "\n",
    "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test_tensor, y_pred_voting))\n",
    "print(\"Voting Classifier Precision:\", precision_score(y_test_tensor, y_pred_voting))\n",
    "print(\"Voting Classifier Recall:\", recall_score(y_test_tensor, y_pred_voting))\n",
    "print(\"Ending Evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 44)\n",
      "(4000,)\n",
      "(4000,)\n",
      "Accuracy: 0.5065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "binary_classifier = LogisticRegression()\n",
    "binary_classifier.fit(X_train_scaled, y_train)\n",
    "print(X_test_scaled.shape)\n",
    "y_pred_log = binary_classifier.predict_proba(X_test_scaled)\n",
    "logits_log = np.log(y_pred_log[:, 1] / (1 - y_pred_log[:, 1]))\n",
    "threshold = 0\n",
    "y_pred_logistic= (logits_log > threshold).astype(int)\n",
    "\n",
    "print(y_pred_logistic.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_model = models.resnet18(pretrained=False)\n",
    "og_model.fc = torch.nn.Linear(512, 44)\n",
    "\n",
    "ckpt = torch.load(\"./01_MIA_67.pt\", map_location=\"cpu\")\n",
    "\n",
    "og_model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2152625/2389518504.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  imgs_out = torch.tensor(mem_out, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "priv_out_dataset: MembershipDataset = torch.load(\"./priv_out.pt\")\n",
    "mem_outputs = []\n",
    "\n",
    "mem_out = og_model(torch.stack(priv_out_dataset.imgs))\n",
    "imgs_out = torch.tensor(mem_out, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_voting = voting_clf.predict_proba(imgs_out)\n",
    "logits_pred_voting = np.log(y_pred_voting[:, 1] / (1 - y_pred_voting[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5608155  -0.63304793  0.70806656 ...  0.02555459  0.61898369\n",
      "  0.31641305]\n"
     ]
    }
   ],
   "source": [
    "print(logits_pred_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = binary_classifier.predict_proba(imgs_out)\n",
    "logits_log = np.log(y_pred_log[:, 1] / (1 - y_pred_log[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"ids\": priv_out_dataset.ids,\n",
    "    \"score\": logits_log\n",
    "})\n",
    "df.to_csv(\"test_log.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TPR@FPR=0.05': 0.049, 'AUC': 0.4913101111111111}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\"http://34.71.138.79:9090/mia\", files={\"file\": open(\"test_log.csv\", \"rb\")}, headers={\"token\": \"40034445\"})\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
